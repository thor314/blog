[{"categories":["crypto"],"content":"  What's that? Anna asked.\n \"It's anything you want it to be,\" said Ted the Tokenmaker.\n \"But that's not a thing,\" said Anna.\n \"That's the magic of crypto,\" said Olly the Optimist, \"the more people believe in these, the more they are.\"\n …\n \"What's that?\" said Alex.\n \"It's anything you want it to be,\" said Anna.\n \"Sounds like magic beans,\" said Alex.\n \"They are until they're not, unless they are, but I like them so who cares?\" said Anna.\n  This article responds to the thoughtful piece by Anna Rose, which is recommended pre-reading, as this piece will attempt to respond to the posed questions: What exactly are NFTs for, and what would make me buy an NFT?\n How to price NFTs is beyond the scope of this article, but I recommend Nic Carter and William Peaster for some useful takes.\nWhat are NFTs for, and Why you might want one  Much of the noise around NFTs stems from the question, what the hell am I going to do with this? An NFT is a sufficiently general technology that, in theory, there are many uses for NFTs; yet in practice, art and gaming have attracted the greatest share of attention. Looming behind these is the spectre of rampant price speculation, divorcing many NFT products from any semblance of intuitive valuations. At its highest echelons, the NFT investment game is being played by DAOs and whales playing a game of chicken, taking turns in bidding increasingly unbelievable amounts, in turn raising the overall value of their impressive collections (which may then be quietly sold for a tidy profit).\n NFTs aren't just for speculation. They're also for status signalling, as Nic Carter of Castle Island Ventures points out:\n Most likely, I’m betting that newly-rich Ethereum enthusiasts will see the NFTs as a kind of totem of status, signalling membership in an exclusive club (people that had the foresight to buy the first NFTs on Ethereum, or the financial clout to buy them once they got popular.) My best thesis here is that these are effectively a form of resalable social signalling, like a digital Hermes Birkin bag. The actual contents of the NFT is largely irrelevant.\n  We see this playing out on Crypto Twitter, where CryptoPunks and MoonCats are becoming increasingly common avatars for prominent crypto community members. Paying the exorbitant price to acquire one of these cements one's identity as a crypto OG, or at least as a community member willing to pay for their status.\n Finally though art NFT prices are wild, prices go to supporting artists and artist communities (assuming you're not being duped into fraudulent art!). Much like any piece of art, if a piece on an NFT marketplace like Mintbase, OpenSea, or Rarible catches your eye enough to warrant purchase, do some research about the artist to verify the piece is non-fraudulent before buying. If you do purchase an art NFT, virtual reality worlds like CryptoVoxels and Somnium Space allow users to show off NFTs inside their virtual property (which of course, you may purchase with an NFT).\n It's worth taking a time-out to address one criticism of NFTs that seems undeserved. Environmentalist critics have accused NFT artists consuming excessive amounts of energy on Proof of Work chains. But as artist Stirling Crispin points out in an excellently researched essay, NFTs account for about 3% of gas consumption on Ethereum, which in turn uses 0.02% of the total Earth CO2 footprint. There are greater obstacles to energy neutrality than a small community of talented people exploring ways to monetize their work:\n The real problem is the giant 72%…it’s fossil fuel subsidies, its coal power plants, its fracking. If your number one motivation is the environment, and you’re behaving rationally, it makes sense to focus on the big things most and the little things least.\n  Further, NFT platforms are not married to Proof-of-Work blockchains. Mintbase gives our users the tools to deploy their own NFT contracts. We opted to add support for the Proof-of-Stake chain NEAR, so that our users may minimize their transaction costs and environmental impact.\n So we've got speculation, status, and support for art and artist communities. I haven't exactly painted a glamorous picture of NFTs, so you'd be excused for the suspicion that NFTs aren't actually that cool. But you'd be WRONG. Downstream from the hype cycle, some great projects are taking form, with NFTs at their core.\n  Like what?  NFTs are a tool for collaboration and creation. The NFT might be best understood as a Public Key for an item or service, on a public database. The departure from a private database model allows for ease of collaboration, while guaranteeing users to the longevity of their data.\n Gaming NFTs, like Dark Forest, Axie Infinity, and Gods Unchained scratch the surface of what's possible, by tokenizing in-game assets, which are easily exchanged on on-chain marketplaces. Further, gaming NFTs can do more than one thing. Imagine if after spending 100 hours grinding in World of Warcraft, the Sword of Coolness item you earned gave you a rare playing card in Hearthstone, a skin in Fortnite, and a ticket to a League of Legends esports event. Since NFTs live on a public ledger, a single NFT can do as many things as there are services willing to attach value to that NFT. Storing game data as an NFT, thereby on a public database, is a departure from prior models, where all data is stored privately. Private databases limit not only users' ability to access and profit from their efforts and data but also limits opportunities for cross-pollination between projects.\n Beyond gaming application NFTs in the decades to come are likely to be a force for standardizing an extensible concept of ownership. Extensible, as the base concept of an NFT is very simple. Simplicity that can be extended as the use case demands, by way of extending the base contract, or else by attaching services to the ownership of an NFT. Much like smartphones have simplified the interface to communication, transportation, and social media, NFTs simplify the interface to ownership of access to goods and services.\n The NFT-maximal future doesn't have much in common with the NFT speculation today, but for that goods and services that can be represented as NFTs will have incentive to do so, so as to take advantage of ease of issuance, verification, integration with other NFT-enabled businesses, and to reap royalty payments for NFT transfers. Users will be able to view, manage, buy, and sell goods and services across domains. Imagine if your gym membership, blog subscriptions, rewards programs, event tickets, and more, could all be managed, bought, and sold within a single application.\n In place of the myriad interfaces we use daily to prove our right of access to goods and services, from tickets to titles to coupons to login credentials, the (1) public, uncensorable verifiability of NFTs, (2) ease of transfer of NFTs, and (3) shared interface to each of these application areas mean that the realm of possibilities of NFT-enabled technology is far-reaching.\n  Wrap up  To recap. What are NFTs for? At the moment, speculation, status signalling, and artwork are the ascendant NFT applications. But NFTs are incredibly flexible as technological tools, and could someday be for lots of things, or at least, much more than what they're currently used for. Gaming applications are allowing users to reap dividends from their play-time, by representing in-game assets as NFTs. And an NFT future could involve much more (maybe after a hype cycle or two).\n The author is a developer at Mintbase, a platform giving users an interface to create and their own NFT minting contracts. We're on Ethereum and have recently launched on NEAR testnet! If you're exploring what's possible with NFTs, check us out.\n first posted at the ZKPodcast blog\n  ","description":"","tags":["nft","crypto","predictions"],"title":"NFT Hype: What’s What and What’s to Come","uri":"/posts/nft_hype/"},{"categories":["crypto"],"content":"  What makes a game a “blockchain game”? A simple definition: some part of the state of the game is stored on a blockchain and is therefore publicly visible. Think chess or tic-tac-toe: each move is a state change on a publicly visible ledger. Compare this to games like League of Legends or Call of Duty, where the game state lives entirely on a private game server.\n Suppose we wanted to store the entire game state on-chain. But then, every player would be able to see the entire “game board” and the position of every opposing player. For games like chess, that’s fine. But can we build a game with hidden information like Civilization where players have only a partial view of their environment and opponents?\n The game Dark Forest is exactly that. By using zkSNARK cryptography (zero knowledge Succinct Non-interactive ARguments of Knowledge), the developers of Dark Forest have designed a universe and created a game where the state is completely stored on-chain. And yet each coordinate is hidden behind a hash that players may compute. This way all participants can explore and conquer a corner of the universe, and what they discover is consistent with what other participants see when they explore that region.\n This article will focus on the game mechanics that the Dark Forest team were able to implement by applying SNARKs, and explore how these schemes push the limit of possible game interaction beyond the limits of prior art, such as commit-reveal schemes.\nThe Game, Succinctly  In the game of Dark Forest, players compete with one another for interplanetary territory. Players begin in complete darkness. A fog of war covers the universe surrounding their home planet. To explore, the browser makes use of players’ local computing power to compute a hash for each coordinate. Thereafter, that coordinate is revealed to the player and the map is slowly explored. Most coordinates contain nothing but empty space, but some contain planets, either uninhabited, or owned by other players. Once a planet is revealed, the browser can check on-chain to see if another player has staked a claim to the revealed rock, and see if other players try to take that planet.\n Beginning with the one planet, a player (let’s call her Alice) publishes state transitions from her original planet to other planets. A state transition moves resources (population and silver) from an owned planet to the discovered planet, thereby colonizing a new planet, or attacking another player’s planet. Moving population between planets is limited by the origin planet’s range and population to move. Players can also upgrade their planets with silver — an in-game resource generated on certain planets that is used to purchase upgrades.\n Planets gradually accumulate resources and, as players discover one another, wars break out over high value planets. However, a player is not guaranteed to know where an attack came from; only if the player has revealed the coordinates of an attacking planet will they be able to see the red line indicative of an enemy movement.\n  What makes the game possible is valid state transitions: how does the game move resources between planets, as on-chain data, without revealing the data, or committing invalid transitions?\n  What can we do without SNARKing?  Here’s the problem: Alice has a planet X with population N, and wants to send n people from X to planet Y, without revealing information about X, N, n, or Y to the rest of the world (state transitions on silver are in effect identical to population, so we’ll ignore them). Alice will have to prove:\n  Ownership of X\n  n \u003c N\n  A ship from planet X with n population has enough range to reach Y\n  Without SNARKs, Alice and company can still set their computers to the task of de-fogging the map: hashing each coordinate, looking for planets. There are two schemes that would allow Alice and company to play: 1) a centralized coordinator, or 2) a commit reveal scheme.\n  Centralized Coordinator Scheme  In the centralized coordinator scheme, Alice and company submit state transitions to a centralized coordinator with a god’s eye view. The coordinator can see X, N, n, and Y, and easily verify that each transition is valid. Most existing games rely on a centralized coordinator.\n However, the centralized coordinator is a target for attacks and collusion, either of which could halt the game or reveal the universe to the attacking/colluding party. It’s not really a “Dark Forest” if someone has a universal floodlight, as is the norm with games on hosted game servers! As a cultural side note, companies who host games on servers assuage players’ fears by creating strong punishments for those caught cheating or attempting to cheat by hacking or other measures: players must trust the company’s promise to seek out and ban cheating players.\n  Commit-Reveal  In a commit-reveal scheme, each participant has some secret s that they want to hide from other players until some event occurs, or after a time delay T. Players publish the hash of their secret, H(s), and reveal the secret after the delay. Poker provides an example: players commit the hash of their cards at the beginning of the round, publishing H(s), and a player reveals the value of s if the hand does not terminate early.\n In Dark Forest, players could agree on a time elapse to reveal their actions. If a player revealed an invalid action after the time delay, they could have some or all of their actions reverted, and optionally be punished in some other way (removal, temporary deactivation, etc). In each period, players would commit the hashes of their actions, H(a_1, …, a_k), and the game could proceed, except that no action would be publicly visible until after the period elapsed, along with X, N, n, and Y.\n The core problem with a Commit-Reveal scheme is that information eventually must be revealed. Actions are only private up to the point of the next period, not for the entire duration of the game. This incentivizes a longer period of play, but a long period slows game pace, without resolving the fundamental issue of keeping game state private. Revealing concealed information at the end of each interval is fine for round-based games like poker, but not for games with a vast global state with a fog-of-war element (or for that matter, any application that would like to keep mutable state elements indefinitely concealed).\n  SNARKing through the Fog of Space  By applying a SNARK, Dark Forest players can submit proofs to the Dark Forest contract that X, N, n, and Y satisfy the necessary conditions. The Dark Forest contract verifies the proof, without ever having to know the values of X, N, n, and Y. Therefore, a player can submit moves and upgrade actions to the smart contract without allowing other players to know the contents of their actions.\n This is almost perfect zero-knowledge. Other players are still able to see the number of transactions submitted by their rivals, and the block at which each transaction was included. From that on-chain information, a rival could determine when a player was most and least likely to be online, thereby receiving hints about when to attack. To eliminate even that information, Dark Forest would have to operate on a blockchain with shielded addresses or a privacy-enabled Layer 2.\n  It’s important to note that this applies to more than just games. Zero knowledge technology has broad application beyond Dark Forest. Experiments with zero knowledge systems are underway in voting systems, financial privacy, authentication without identification schemes, and even nuclear disarmament. In a broader context, the power of zero knowledge schemes is to conceal participants’ private information, while guaranteeing honest system-interaction. The Dark Forest zero knowledge game may serve as an approachable introduction to a field that has been respectfully referred to as “moon math”, in reference to its complexity. By bringing broader awareness to this technology, Dark Forest is a harbinger of novel zero-knowledge enabled experiments and applications, introducing the advantages of greater privacy and security in new ways.\n first posted at the ZKPodcast blog\n  ","description":"","tags":["zeroknowledge","cryptography","game","explainer"],"title":"Zero Knowledge: The Game","uri":"/posts/zero_knowledge_game/"},{"categories":["rust"],"content":" Tipping Cows, a Primer on Rust's Most Bovine Data Structure  The year was 2020. An epidemic swept across the globe, driving all human life indoors. Unrest concerning police action and longstanding racial inequality in the US drove the very same back into the streets. Like cattle, driven back and forth we were, with global sociopolitical and health trends our ranger.\n In other words, there was never a better time to read an primer on Cows. Yes, those magical moo-ers. No, that was a lie. This is going to be about the Cow data structure in Rust, systems programming language and global phenomenon, sorry for the confusion.\n So now that I've lied to you once, I hear you asking \"Why should I stay?\" Well. I offer ye nothing less than knowledge of dark bovine arts. Along the way you'll be sprinkled with Rust language insights and regular attempts at cow-humor.\n When you've finished this cool glass of milk, you will know what a Cow is doing when you spot one (in Rust that is, for the alternative consult a local farmer), see several examples of Cow in practice, and maybe even raise your own Cows. Like this. If you're unfamiliar with smart pointers, lifetimes, or the borrowing/ownership system in Rust, don't panic. They're totally on the docket. Cowabunga.\n But if you're new to Rust, you might consider first visiting one of the many great explainers of how the compiler helps us avoid careless reference errors by way of its borrow checker. But if you're not here to click links, here's the basic idea:\n Similar to C and C++, Rust doesn't have a garbage collector: a process that runs in a program's runtime that tracks which variables reference what data, and when that data will no longer be used, so that memory can be freed up. Most languages (Python, Java, Javascript, C#, Go, etc.) have a garbage collector, which is how they manage memory. In C and C++, memory and references are generally managed by the programmer (and sometimes, programmers make memory management mistakes that may not be obvious until things break). In Rust, the borrow checker does memory management for us, which is ergonomic (don't have to manually manage memory), safe (prevents security errors and issues, especially in concurrent programs), and fast (on par with C and C++). By strictly enforcing a couple rules about mutable and immutable references, we get these nice things.\nEnter Cows  If we run over to the Zoo of Rust's Creatures, we find a Cow in captivity:\n1 2 3 4 5 6 7  pubenum Cow\u003c'a,B\u003ewhereB: 'a+ToOwned+?Sized,{Borrowed(\u0026'aB),Owned(\u003cBasToOwned\u003e::Owned),}    The zoo helpfully informs us,\n_________________________________________ / The type Cow is a smart pointer \\ | providing clone-on-write functionality: | | it can enclose and provide immutable | | access to borrowed data, and clone the | | data lazily when mutation or ownership | | is required. The type is designed to | | work with general borrowed data via the | \\ Borrow trait. / ----------------------------------------- \\ ^__^ \\ (oo)\\_______ (__)\\ )\\/\\ ||----w | || ||   Moo. That's a lot to parse. There's roughly three concepts baked into that definition:\n  What is clone-on-write functionality, and what's the diff to copy-on-write\n  Why this elitist smart pointer\n  Where do lifetimes enter in\n   If you know the answer to all of those questions, you can probably skip ahead to examples. Don't know? Read on!\n Let's start with why we care about these concepts: what do we win if we collect them all? Well, in simplest form, we win an runtime optimization technique, for when the data we're handling will sometimes be acceptable to immutably borrow (which is cheap), but other times will have to be owned, which would happen if we had to mutate the data in some way. Back to the concepts.\nCopy-on-Write vs Clone-on-Write  Copy and Clone in Rust mean different things. In the non-Rust world, copying usually means reproducing the data at a new location. This is cloning in Rust. Copying is simpler and less expensive: reproduce the data if it's statically sized (ints, floats, bools, etc), or reproduce the pointer if the data is dynamically sized (Vec, String, HashMap, etc). Copying usually happens implicitly; meaning the compiler just does it for us, no muss, no fuss. Cloning, not so: we have to explicitly tell the compiler to clone the data. Any data that can be copied (only fixed size) can also be cloned (fixed or dynamically sized); the reverse is not true. Copy is cheap, Clone is expensive.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  // u32 implements Copy leti: u32 =42;leti_copy=i;// copy occurs implicitly println!(\"Can use original int and copy: {}, {}\",i,i_copy);leti_clone=i.clone();println!(\"Can use original int and clone: {}, {}\",i,i_clone);// String implements Clone but not Copy. lets: String::From(\"Don't Panic\")lets_clone=s.clone();println!(\"Can use original string and clone: {}, {}\",s,s_clone);// this will fail, since String does not implement Copy // let copy_s = s;       Smart Pointers are Runtime Friends  They say runners are are smart (don't ask who \"they\" are, I'm sure they're out there somewhere). And Smart Pointers are your running friends. Smart pointers were introduced by C++ in the 1990s as a tool to manage resources related to the memory they're pointing to. Like Rust, C++ doesn't have automatic garbage collection, and smart pointers were invented to prevent memory leak situations. Rust does it's best to manages memory without a garbage collector at compile-time with it's ownership system, but at runtime, it's all smart pointers. That's why smart pointers aren't generally a necessary concept to anyone coming from a garbage collected language, like Java or Python (though Java does have a cow).\n In the context of Cows, the Cow smart pointer acts like a normal pointer when it merely borrows data, but at runtime, the Cow smart pointer can take ownership of the borrowed data. This is more expensive than borrowing the data: a borrow only requires the borrower to keep a reference to the data, wherever it is. But taking ownership requires the data to be cloned, meaning the runtime will have to reproduce the data on the Heap (whenever we allocate memory in runtime, it's usually safe to assume it's happening on the heap). If the data is particularly large, (a long string or text file, for instance), lazily cloning only when it becomes obviously necessary is a useful optimization.\n1 2 3 4 5 6 7 8 9 10  usestd::borrow::Cow;fn lazy_abs(input: \u0026mutCow\u003c[i32]\u003e){foriin0..input.len(){letv=input[i];ifv\u003c0{// Clone into vector if not already owned input.to_mut()[i]=-v;}}}    From Rust's Cow documentation.\n  Where do lifetimes enter  Lifetimes tell the borrow checker when a borrow is going to end. When a Cow borrows some data, the Cow should never outlive the data. Further, if the Cow takes ownership of the data with a clone, it makes sense that the cloned data still shouldn't outlive the original data. Rememer how we defined Cow? You don't have to, here it is again.\n1 2 3 4 5 6 7 8  pubenum Cow\u003c'a,B\u003e// Cow doesn't outlive data with lifetime 'a where// if Cow takes ownership, stay with the herd, keep lifetime 'a B: 'a+ToOwned+?Sized,{Borrowed(\u0026'aB),// Borrow a generic reference to data B, with lifetime 'a Owned(\u003cBasToOwned\u003e::Owned),// We haven't gotten here yet. }        Putting it all together  You made it this far cowpoke. Hold onto your milk, because it's time for a pop quiz.\n Suppose we've got a struct containing an immutable generic vector. How would we update it to wrap a Cow?\n1 2 3 4 5 6 7 8 9  struct VecWrapper\u003cT\u003e{v: Vec\u003cT\u003e,}impl\u003cT\u003eVecWrapper\u003cT\u003e{fn new(v: Vec\u003cT\u003e)-\u003e Self{VecWrapper{v}}}     Well, for starters, we're going to need to import Cow, add lifetimes, and modify some definitions. Let's sprinkle lifetimes everywhere a generic definition appears, and wrap our Vector in a Cow.\n1 2 3 4 5 6 7 8 9  usestd::borrow::Cow;struct VecWrapper\u003c'a,T\u003e{v: Cow\u003c'a,Vec\u003cT\u003e\u003e,}impl\u003c'a,T\u003eVecWrapper\u003c'a,T\u003e{fn new(v: Cow\u003c'a,Vec\u003cT\u003e\u003e)-\u003e Self{VecWrapper{v}}}    error[E0277]: the trait bound `T: std::clone::Clone` is not satisfied --\u003e src/lib.rs:5:3 | 5 | v: Cow\u003c'a, Vec\u003cT\u003e\u003e, | ^^^^^^^^^^^^^^^^^^ the trait `std::clone::Clone` is not implemented for `T` | = note: required because of the requirements on the impl of `std::clone::Clone` for `std::vec::Vec\u003cT\u003e` = note: required because of the requirements on the impl of `std::borrow::ToOwned` for `std::vec::Vec\u003cT\u003e` help: consider restricting type parameter `T` | 2 | struct VecWrapper\u003c'a, T: std::clone::Clone\u003e | ^^^^^^^^^^^^^^^^^^^ ...   Well, it was a noble first try. In the wise words of Rust Sage Gankra, \"It should be noted that the authentic Rust learning experience involves writing code, having the compiler scream at you, and trying to figure out what the heck that means.\" We're living that dream. But the rust compiler is actually pretty helpful here. We need to put a trait bound on T, so that our pet Cow can clone T if and when it needs to.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  usestd::borrow::Cow;struct VecWrapper\u003c'a,T: Clone\u003ewhereT: Clone {v: Cow\u003c'a,Vec\u003cT\u003e\u003e,}impl\u003c'a,T\u003eVecWrapper\u003c'a,T\u003ewhereT: Clone {fn new(v: Cow\u003c'a,Vec\u003cT\u003e\u003e)-\u003e Self{VecWrapper{v}}}    warning: struct is never constructed: `VecWrapper` --\u003e src/lib.rs:2:8 | 2 | struct VecWrapper\u003c'a, T: Clone\u003e | ^^^^^^^^^^ | = note: `#[warn(dead_code)]` on by default ...   Success! If we wanted to take our implementation one step further, the documentation gives an example of wrapping a generic array with a Cow, which would require a couple more trait bounds.\n1 2 3 4 5 6 7 8 9 10  usestd::borrow::Cowstruct Items\u003c'a,X: 'a\u003ewhere[X]: ToOwned\u003cOwned=Vec\u003cX\u003e\u003e{values: Cow\u003c'a,[X]\u003e,}impl\u003c'a,X: Clone +'a\u003eItems\u003c'a,X\u003ewhere[X]: ToOwned\u003cOwned=Vec\u003cX\u003e\u003e{fn new(v: Cow\u003c'a,[X]\u003e)-\u003e Self{Items{values: v}}}    Which ends up looking pretty close to our vector wrapper, but since the Vec type implements ToOwned for us and the array doesn't, a we'd have to implement `ToOwned` for our generic array by hand.\n Alright, so there's a lot more that can be done with Cows than we got into here. But I'm hoping this was enough of a prod to get you up and mooving with cows. Thanks for joining me, and best of luck in all your future Rust endeavors.\n  Sources:  Documentation std::borrow::Cow\n Smart Pointers Wikipedia\n Secret Life of Cows\n    ","description":"all about the Clone-on-write Rust data structure","tags":["rust","programming"],"title":"Tipping Cows, a Primer on Rust’s Most Bovine Data Structure","uri":"/posts/cows_in_the_wild/"},{"categories":null,"content":" Passionate about building better systems of economic and human organization.\n If you're in Lisbon, reach out on Twitter: @cryptograthor\n","description":"","tags":null,"title":"About","uri":"/about/"},{"categories":["society"],"content":" I wrote this paper as a course paper in sustainability and innovation at the University of Oslo. In the section before the conclusion I propose an original (possibly not, but I didn't find it elsewhere) system for coordinating government agreements around international policy.\nAbstract  Climate change presents a pressing range of tragedy of the commons problems, eg. global sea level and atmospheric carbon dioxide concentration. Barring the reduction of democracy to technocracy, there is a niche for innovation in the methodology employed by political bodies toward assessing solution quality and the probable outcome landscape of implementing a policy or resolution. Multilateral policy agendas coordinated between political actors represents one such opportunity. Attempts at collective action solutions often result in the emergence of tragedy-of-the-commons problems. I will analyze the tragedy-of-the-commons failure as pertaining to international climate summit resolutions, and introduce several implementations of prediction markets as a possible solution to the problems incumbent to global climate agreements, and tragedy-of-the-commons problems more generally.\n  Introduction  Global climate summits an example of the tragedy-of-the-commons problem: political actors employ the ecopragmatist-originated sustainable transformation rhetoric as umbrage for resolution-reneging political failures, while the political incentive to meet international climate summit commitments is regularly outweighed by competing local political factors. Incentivizing multilateral follow-through on climate agreements requires addressing several sub-problems. I will address and analyze the problems incumbent to the present system of climate resolution. Then I explore technocracy as a naive solution to the political problem of information aggregation. Then I will introduce prediction markets, applied to these problems in two possible implementations. Last, I will discuss some of the more common criticisms with prediction markets.\n  Criticisms of the 2030 Agenda for Sustainable Development  The 2030 Agenda for Sustainable Development and SDGs [a], adopted in 2015 by the UN, outlines 17 goals and 169 targets for reducing poverty and engaging sustainable practices in participating nations. One might infer from the self-congratulatory language used on the website of the European Union that the Agenda’s success is all but assured: “the adoption of the 2030 Agenda was a landmark achievement, providing for a shared global vision towards sustainable development for all.” Claims to the contrary are in evidence. 425 days after the adoption of the Agenda (in 2016), “tangible progress in terms of implementing the SDGs at the country level has been hard to come by” [c], and in the 2019 SDG report, United Nations Secretary-General António Guterres wrote “it is abundantly clear that a much deeper, faster and more ambitious response is needed to unleash the social and economic transformation needed to achieve our 2030 goals” [d]. One obvious problem is the excessive use of vague language in the agenda’s goals, eg. “3. Good Health and Well-Being for people– Ensure healthy lives and promote well-being for all at all ages”, in combination with ludicrously overzealous goals, eg. “1. No Poverty-End poverty in all its forms everywhere.” A child might have written these. For these among other reasons, the SDG goals were called “worse than useless” by The Economist in 2015 [b]. The document continues “All countries have a shared responsibility to achieve the SDGs.” To clarify: the term “shared responsibility” is political umbrage, indicative of no responsibility at all. Political leaders’ motives at summits such as these are not to acquire the relevant information, assemble coherent policy agendas, or otherwise solve any problems at all, but to author rhetorical nonsense, while pretending to be doing something. A better system for aggregating the relevant information and constructing coherent policy agendas is in need. Before proposing an alternative, I analyze some of the problems inherent to the present system. [a] https://ec.europa.eu/environment/sustainable-development/SDGs/index_en.htm [b] https://www.economist.com/leaders/2015/03/26/the-169-commandments [c] https://www.idea.int/sites/default/files/news/16-11-22-The_slumber_of_the_SDGs.pdf [d] https://www.un.org/sustainabledevelopment/progress-report/\n  Problems Inherent to International Policy Consensus  Three key problems emerge in the UN methodology in designing and implementing goals. The first has to do with the distributed nature of responsibility for implementing policy, resulting in a tragedy-of-the-commons problem. The second has to do with the existing processes by which existing information is aggregated into resolutions and policies. The last has to do with the reporting and accountability process, after resolutions and policies are put in place. The distributed nature of responsibility among United Nations member nations decreases the degree of accountability any particular nation holds in following through on its commitments, eg. As member countries A and B commit to reducing it’s net carbon footprint, country B benefits from country A reducing its carbon footprint, but pays none of the costs incurred by decreasing country B’s own footprint. Thus country B has incentive to renege on its agreements while saddling country A with the costs. The scale of the problem increases with the number of countries, and their relative power differential. For instance, in our previous example, if country B is economically or militarily dependent on country A, country A has further less incentive to sacrifice immediate economic productivity to satisfy an international agreement. This puts weak nations in an impossible political situation, as Leichenko and Silva identify that “not only are the poorest and most marginalized disproportionately affected, but climate change impacts can also exacerbate existing inequalities” [e]. Note that country A may still enter an agreement with no intention of holding to it, so as to enjoy the benefits of other nations’ carbon footprint reduction while paying none of the costs. This provides context for how all 193 of the member countries of the United Nations committed to the SDG agenda, while funding for achieving these goals is 2.5 trillion dollars short of the 5 trillion per annum price tag [f]. The incentive to defect from agreements is a hallmark of the Tragedy-of-the-Commons problem. Holding to the international agreement is in direct competition with satisfying interest groups, promoting economic activity, and securing local objectives. Solving tragedy-of-the-commons problems requires optimization in selecting realistically limited objectives, implementing effective policy to resolve those objectives, and measuring results. Beginning with rational information acquisition, we may ask the question, how well informed with respect to realistic outcomes is current policy? Given that only 2 of the 17 SDG goals are currently on track, it seems safe to conclude: not very. This is a characteristic property of democracy: from the local to the international, voters have little chance to be pivotal in voting, irrational in selecting realistic policy paths, under-informed in policy relevant to them, and tribal in their ultimate policy preference. Their representative politicians, responsible to their constituents, reflect these failures in information aggregation. In this system, relevant information for policy selection is regularly subverted to tribal preference, miscommunicated by media, deprioritized on the basis of technicality, or never brought to light in the first place. The result is the commitment toward ineffective and unrealistic solutions, as in the case of the 17 SDGs. As the power for humans to effect changes on our environment monotonically increases with time, political systems incorporating such failures as these doom the quality of our political decisions. [e] https://onlinelibrary.wiley.com/doi/abs/10.1002/wcc.287 [f] https://www.nature.com/articles/d41586-019-03907-4\n  Naive Solution: Technocracy  The most naive solution to the criticisms above, in particular with regards to climate action as a primarily scientific and economic domain of policy, would be to simply reduce the poIr of our representative democracy with respect to policy decisions inside certain domains, reallocating the poIr to shape policy to the set of experts perceived to be most relevant. Political systems in this arrangement are referred to as technocracies, and emerge commonly in businesses requiring technical expertise. Though a full analysis of the merits and weaknesses of technocracy is beyond the scope of this paper, a brief treatment of the most relevant problems of technocracy will prepare the ground for prediction markets. Technocracy’s primary advantage in practice is an approximation of meritocracy flavored towards elevating the hierarchical importance of fact-based reasoning and technical ability to engage a somewhat predefined domain of technical problems. The first problem in technocracy one might encounter is a problem with the very definition of what constitutes an “acceptable group of relevant experts.” Each word presents myriad problems. Acceptable to whom? Being acceptable to the public reduces our group of experts to little more than politicians. Being acceptable to other experts (if such a group even exists) exposes age bias, and is still vulnerable to a certain degree of politicking. Does relevant indicate the group should represent a sampling of interdisciplinary fields or should it be more constrained? Should the group’s participants be a dynamic set or a static one? What about overlapping expertise groups? This is to demonstrate that the problem of electing a set of experts in a democracy is quickly reduced to the problem electing politicians. Were it politically popular to elect expects, such would already be the status quo. Even presupposing a mechanism for expert committee selection, a second class of political problem exists: technocracies are aristocracies with a chrome polish. That is, technocracies are closed political systems; once established, members of a technocracy could gate-keep even other experts out of the technocracy. This is acceptable in business, where gatekeeping takes the form of filtering new hires, but not in government, where a political near-invulnerability to criticism is unacceptable. Finally, the problem domains in which technocracies thrive often allow for the opportunity for a posteriori improvements to solutions. Political environments are hostile to iterative policy change; that is, the cost of renegotiating policy decisions is high. Further, there are economic productivity losses in volatile policy environments. Thus policy technocracies are subject to the same constraint restriction of the existing democratic system: policy construction must optimally aggregate the available information landscape while navigating the political network. This implies that the information aggregation problem exists in isolation to the chosen political regime, suggesting that there may be better solutions to the problem of information aggregation with respect to the construction of policy decisions than resorting to a cabal of politically unaccountable domain experts. Prediction Markets in Assessing Policy Directions To my best knowledge, prediction markets were introduced as having potential as a democratic process by economist Robert Hanson [g]. Hanson proposed that “inferior policies happen because our info institutions fail to induce people to acquire and share relevant info with properly-motivated decision makers.” Hanson identified inferior processes for generating and evaluating information relevant to governing as responsible for economic divergence between democracies, and proposed prediction markets as a solution. Prediction markets are effective at aggregating information about the probable outcomes of a proposed action. By their application to policy, nations may optimize policy selection, while resolving an incentive mechanism to counteract the tragedy-of-the-commons problem. Note that the ability of prediction markets is limited to expressing probable outcomes of policy alternatives, not in expressing what outcomes are qualitatively better than one another. Participants in a prediction market bet on the outcome of a particular event by an agreed upon point in time. For example, suppose at time t=0, a prediction market opens around whether policy A will achieve event Z by time t=T. Bettor 0 believes the outcome is likely, and bets $70. Then at time t=1, bettor 1 believes the outcome is only 70% likely to occur, so bettor 5 bets $30 against. The betting market now reflects a 70% chance of action success. If no further bettors enter, and the result is positive, the first seven bettors split the $30 counterbet, and if the result is negative, bettor 1 takes the $70. But now suppose an alleged domain expert, bettor 2, sees the 70% betting odds, and thinks the odds are much closer to 40%. If bettor 2 is correct, he will profit off of making any bet moving the odds closer to 40%. He does so by betting $75 against. The prediction market thereby incentivizes all domain experts, regardless of credentialing, to apply their knowledge for the public interest. This system avoids the closed property of technocracies’ only allowing for the expressed opinions of a narrow, preselected group of experts, while simultaneously allowing for democracy to take place around the most engaged, informed, and affected constituents. Statistics reflect this: in one study, prediction markets around elections were found to be 74% more effective than polling over 964 elections, with an even greater advantage in forecasts beyond 100 days [h]. In the context of policy selection, a political committee could propose several policy alternatives to a betting market in reference to their ability to achieve some outcome. After some waiting period (requiring some mechanism to avoid allowing last minute interference bets), the committee could then implement the policy alternative seen as most likely to succeed, and reset all markets of policy alternatives not taken. One of the most common criticisms of prediction markets as a vector to inform policy decisions is the opportunity for interest groups to tip the scale by betting overwhelmingly in their preferred direction. But placing restrictions on the maximum bet should not be necessary. The event of an interest group betting tremendously in one direction should be seen as a tremendous arbitrage opportunity for prediction market participants, as the interest group is not strictly buying “votes” per se, but expressing an opinion concerning the likelihood of an outcome. For instance, if a petroleum company sought to sabotage a prediction market around the probability that policy A achieves outcome Z by betting overwhelmingly that an alternative policy B achieves outcome Z better than policy A, bettors are incentivized to take the counter-bet of petroleum company on policy B, reaping an arbitrage opportunity. This is because bets are not votes: votes are expressions of preference (which deserve discussion in a paper in their own right), bets are expressions of belief about the state of the world, and the consequences of a given action. [g] http://mason.gmu.edu/~rhanson/futarchy2013.pdf [h] https://www.sciencedirect.com/science/article/abs/pii/S0169207008000320\n  Prediction Markets as Staking Mechanisms  Bets are mechanisms for forcing alignment between beliefs and actions. Among the problems inherent to the tragedy-of-the-commons is that actors are incentivized to lie about intentions, or to otherwise express under-calibrated opinions. In addition to their role in information aggregation, prediction markets can serve a mechanism for constructing stake in international policy agreements. A staking mechanism is a procedure in which a participating party accept some quantity of risk, for one or more of the following purposes: (i) as collateral against the party to breaking agreements, (ii) as a signaling mechanism intended to encourage further action by other parties, ie. the public, (iii) as a substitute for, or complement to reputation, in systems where reputation is insufficient in one of the two above ways, (iv) as a bet on a particular outcome with some probability and expectation of returns with positive expected value (v) from the perspective of an observer to the staking process, a mechanism for collecting information about the belief state of participants in the staking system. All but definition (iv) are directly relevant to the discussion of inducing actors to commit to and engage in a more desirable set of actions, in particular, with respect to preserving the environment among other desirable outcomes. A proposed system for international politics could proceed as follows: First, a desired outcome is determined, for instance, a k% reduction in carbon footprint by each nation within 3 years, where each nation gets to choose their value for k, but exponentially increasing upfront costs to a nation’s choice of k below some value. Nations would be required to bet some minimum percentage of their GDP as stake toward meeting their target. Finally, delegates from each nation would proceed to place bets on each other nation’s objective being met with and against that nation’s staked bet. This system has several advantages. First, it avoids a one-size-fits-all problem of international politics: policy that is effective or reasonable in one nation may not at all be in another. By calibrating goals with respect to each nation, we avoid the problems inherent to the SDG goals’ being simultaneously vague and exaggerated. Second, if nation A’s delegates bet that nation B succeeds at meeting its policy goal, nation A is incentivized to pressure and assist nation B in meeting that policy goal, fostering international cooperation, rather than creating opportunity for defection from agenda agreements. Third, the process creates a reasonably interesting opportunity for popular engagement in international politics. An international betting market between nations would be the international policy equivalent of the Olympics, and would likely draw a great deal of popular attention, raising the stakes for failing to meet commitments.\n  Conclusion  I have analyzed several problems with the international political process, embodied in the 2015 SDGs, and proposed two possible implementations of prediction markets as solutions for rationally aggregating information. I introduced technocracy as a toy solution to better information aggregation, and explored the undesirable properties inherent to that solution as an alternative for eliminating the irrationality inherent to democratic processes. I aimed to attempt to solve the tragedy-of-the-commons problem emergent in international politics, while identifying the economic mechanism failures of the existing process.\n  Bibliography  Berg, J. E., Nelson, F. D., \u0026 Rietz, T. A. (2008, April 28). Prediction market accuracy in the long run. Retrieved from https://www.sciencedirect.com/science/article/abs/pii/S0169207008000320 Get the Sustainable Development Goals back on track. (2020, January 1). Retrieved from https://www.nature.com/articles/d41586-019-03907-4 Hanson, R. (n.d.). Shall We Vote on Values, But Bet on Beliefs? Retrieved from http://mason.gmu.edu/~rhanson/futarchy2013.pdf Leichenko, R., \u0026 Silva, J. A. (2014, May 2). Climate change and poverty: vulnerability, impacts, and alleviation strategies. Retrieved from https://onlinelibrary.wiley.com/doi/abs/10.1002/wcc.287 Sustainable Development Goals Report - United Nations Sustainable Development. (n.d.). Retrieved from https://www.un.org/sustainabledevelopment/progress-report/ The 169 commandments. (2015, March 26). Retrieved from https://www.economist.com/leaders/2015/03/26/the-169-commandments The 2030 Agenda for Sustainable Development and the SDGs. (n.d.). Retrieved from https://ec.europa.eu/environment/sustainable-development/SDGs/index_en.htm Vandemoortele, J. (2016, November 22). How to bring the SDGs out of their current slumber? Retrieved from https://www.idea.int/sites/default/files/news/16-11-22-The_slumber_of_the_SDGs.pdf\n  ","description":"prediction markets applied to solving international agreements incentive problems","tags":["technocracy","prediction markets","school","environmentalism","futarchy"],"title":"Leveraging Prediction Markets to Mitigate the Tragedy of the Commons Problem in International Climate Change Agreements","uri":"/posts/prediction_markets_climate/"},{"categories":["book"],"content":"  23 books, 3 unfinished with no intention to finish anytime soon. 5 fiction, 18 nonfiction (would it be cheeky to count The Little Bitcoin Book as fiction?)\n Trends:\n  non-fiction especially about business, identity, and climate science early on\n  Biographies and Neal Stephenson towards the end\n  I'll give a couple sentences of my thoughts about each book and a rating out of 10.\nThe books:  Climate and Society, Robin Leinchenko and Karen O'Brien  Information sparse, introduces the integrative approach to climate change solutions. Well researched, useful to get a bearing on the complexity of proposing a \"solution\" to climate change, but prolix. 7/10\n  The Ecology of Commerce, Paul Hawken, unfinished  Hawken is an ecological warrior whose writing should be dated given its publication date of 1992, yet one could rewrite the book today with few changes. Lends support to the conclusion that the environment is doomed and our static political systems are to blame. Unfinished because the book is repetitive. 6/10\n  The End of Jobs, Taylor Pearson  The 4 hour work week, but 10 years later and less interesting. Was interested in his blog, not polished or content dense enough to justify a book. 3/10\n  What You Do is Who You Are, Ben Horowitz  Great read on values, stories about vivid figures from history who demonstrate values in motion, which Horowitz terms \"virtues\", borrowed from samurai literature. Less interested in the business anecdotes, but Horowitz is all around a great story teller. May reread. 9/10.\n  A Liberated Mind, Steven C. Hayes  Hayes is the father of Acceptance and Commitment Therapy. All the feely goody bubbly nonsense anecdotes therapy is infamous for, but not without a complete lack of substance–Hayes delivers the principles of ACT effectively, despite himself. 7/10.\n  Sapiens, A Brief History of Humankind, Yuval Noah Harari  Overrated, but not by much. Seemed like a good thing to read to kids, if I had any. 8/10\n  The Hard Thing about Hard Things, Ben Horowitz, reread  Reread after WYDiWYD. Hard thing about hard things is, as with the next book, about taking the hard things in your hands, communicating honesty in business and in life. Horowitz weaves lessons into the story of his time as CEO of Loudcloud, and a great storyteller he is. 9/10.\n  Models, Attract Women Through Honesty, Mark Manson  An exploration of masculinity, an area of conversation I find underrated, possibly because it only seems to happen when men talk about dating. Book cogently delivers on its premise, investigating the particulars of holding honest as a value, and using it to connect with others (including women). 9/10\n  Homo Deus, Yuval Noah Harari, unfinished  Worse than Sapiens due to a greater degree of speculation. Harari is more in his element in 21 Lessons and Sapiens. Was often bored. 6/10.\n  Range, Why Generalists Triumph in a Specialized World, David Epstein  This book and the next fall into my \"standard MBA business book\" category, delivering loosely connected anecdotes and studies as defenses of an over-general principle. Barely managed to finish each of them. This one did it better. I'm squarely in the target audience for each and was constantly bored. 6/10. Rebel Talent, Why it Pays to Break the Rules at Work and in Life, Francesca Gino 5/10.\n  Tribe, On Homecoming and Belonging, Sebastian Junger, reread  Junger's message in Tribe is clearer than Lake Tahoe, and timeless as her mountains. Conciseness is underrated; Junger delivers in 180 short pages several well constructed narratives highlighting our separation from one another, and how we may come together again. 10/10.\n  Talking to Strangers, Malcolm Gladwell  Depressingly the opposite of the above. Gladwell's winding narrative style is acceptable when he has more to say. He remains an excellent, if somewhat roundabout narrator. I found the premise–that we underrate the value of context and overrate the importance of identity–uninspiring. 7/10.\n  Words and Rules, Steven Pinker, unfinished  A book only a linguist could love, or finish. Long, thorough, and by the sixth chapter, too systematic for even a man with Aspergers. 6/10\n  The Little Bitcoin Book, The Bitcoin Collective  Useful in offering the Bitcoin maximalist system of the world. I'd wanted to get a better idea of what this system of the world was, and especially found it in chapter 5, which offers a pair of speculative anecdotes of the world in 2030 with and without decentralized currency. Conciseness is good. 9/10.\n  Emmy in the Key of Code, Aimee Lucido  What a delightful and unusual children's book this is, discovered through the Embedded.fm podcast. A collection of poems from the perspective of a musical child struggling to find herself in a new place. Struggles with chauvinism, self discovery, appeals to the similarity of code and poetry, musical references, and an utter delight. 10/10.\n  Hackers and Painters, Paul Graham, reread  The best collection of essays I've ever read on what it is to be a hacker, beyond the obvious: we make stuff. The first chapter, about the quality of education (despite my general agreement with most of the premises), was arguably the worst. The remainder of the book is a welcome investigation into value, hacking, and what it is to be a technologist, without fear of delving deep. 10/10.\n  King Lear, 'ol Bill Shakespeare  Unrateable: a low rating marks me as uncultured swine, and a high rating suggests a mastery of Shakespeare I am yet to attain. I continue to find reading Shakespeare as challenging and worthwhile a literary exercise as the best mathematical exercise.\n  Elon Musk, Ashlee Vance, reread  Reread this biography a few months after the more recent controversies of Musk's making an ass out of himself to see if I still resonate with his story and self image as a man possessed to make an impact in the world. I do. It's interesting that he seems content to piss off people so much, something I feel I nearly understand, but just somehow miss. The biography is excellent, and makes me want to defend him. It also makes me want to be like him, which I'm only somewhat uncomfortable with. 10/10.\n  Steve Jobs, Walter Isaacson  I wanted to compare the Musk biography to another pivotal figure, who exists in the same strata of obscenely multitalented entrepreneur defining and propelling the boundary of technology. I'm unsure if it's simply a testament to Vance's ability as a biographer, or if I simply resonate more deeply with the Musk story, but I came away from the Jobs biography with a certain, \"why do I care again?\" taste in my mouth. The early half of the book felt more alive. Maybe this is my becoming a Wozniak fan. 7/10.\n  Atmosphæra Incognita, Neal Stephenson  Stephenson at his shortest. In 100 pages or so, Stephenson lets loose a short story of the tallest building mankind could ever construct. The story appears to be an allegory for technology, progressively hoisting mankind to uncharted heights, with newfound danger and excitement at each new level. I can't stop reading Stephenson after this. 10/10.\n  The Diamond Age, Neal Stephenson  Snow Crash (read in December) was fantastic, but only periodically ran as deep as I would have liked. The Diamond Age scratches that itch. Stephenson trots out a gorgeous fragmented world replete with a new element: nanotechnology. Deftly exploring coming of age, what it means to be a hypocrite, moral life in a corrupt society, the education of a subversive, and the difference of having everything one needs and having everything one needs to build that which one needs, I'm captured with The Diamond Age world, and its protagonist. 10/10.\n  Anathem, Neal Stephenson  I wanted The Diamond Age to be Stephenson at his best. I wanted to think, alright, I can stop reading Stephenson now. I especially wanted to avoid reading 2700 pages of the Baroque cycle. But after this, I think I'm doomed to read everything Stephenson ever wrote. I'm absolutely taken by the world building, the allegories to mathematics and technology, the incorporation of astronomical physics and the multiple worlds hypothesis, and of course, Neal Stephenson's uncanny ability to bring his characters to life. 10/10.\n    Current    Snow Crash, Neal Stephenson, rereading\n  Turing's Cathedral, George Dyson, reading slowly\n  Disunited Nations, Peter Zeihan, Roy Worley, unsure if I'll finish\n    On the \"soon\" List:    The Critique of Pure Reason Kant, forever procrastinating\n  Reprogramming the American Dream, Kevin Scott, Greg Shaw\n  The Sovereign Individual James Dale Davidson, Lord William Rees-Mogg\n  Evidence for Hope, Kathryn Sikkink\n  Radical Markets Eric Posner, Glen Weyl, a reread\n  The Machinery of Freedom, David D. Friedman\n  The Baroque Cycle, trilogy Neal Stephenson\n    ","description":"I review the twenty or so books I read this quarter","tags":["book","review"],"title":"2020 Jan-Mar Book Review Rundown","uri":"/posts/2020_jan_mar_book_review/"},{"categories":["book"],"content":" Review  Rating: 7/10* (9/10 for the first six chapters)\n AI Superpowers is an China-optimistic perspective from a Chinese venture capitalist on the state of advancing competition between China and the rest of the world, which one might (understandably) believe was only Silicon Valley after having read this book. In the first several chapters, Lee sets up a framework to defend his optimism for Chinese firms potential to compete in artificial intelligence by contrasting Chinese entrepreneurial culture to Silicon Valley’s, and drawing stark contrasts between American and Chinese governments approaches to their respective technology industries. Some of Lee’s claims require scrutiny, including his bolstering for Chinese government, borderline-advocacy of ruthless business practice, and characterization that Silicon Valley is pitting elite researchers against Chinese good-enough engineers. However, the book is an invaluable resource for anyone seeking to gain better understanding of how entrepreneurship operates in China, and how the rising Chinese technology economy may overwhelm expectations as an unprecedented powerhouse in emerging technology areas. My interest I suspect the emergence of China as a technological superpower bodes ill as a spectre of things to come with regards to the Chinese reputation of undermining humanism and political freedoms.\n Lee’s deconstruction of AI as a field is most comprehensive in the middle of the book. Lee gives a careful analysis of the four application “waves” of Artificial Intelligence, in considering those that Chinese firms will be most competitive in. He weighs questions about “grid” versus “battery” approaches to artificial intelligence. Championing for the Chinese government’s inefficient, yet clear, approach to stimulating growth with massive incentives, and invasive data collection practices, Lee’s analyses are sometimes poetic, but always optimistic.\n In the last half of the book, Lee (rather abruptly) changes topic. His close encounter with cancer drives him to climb a mountain, to talk to a monk, to celebrate a volunteer golf cart driver, and finally present his thesis on how AI tech has the capacity to displace whole societies. His last two chapters describe what we as a society might do to limit the negative consequences of what will be gradual but massive displacement and unemployment. Though I'm persuaded that society will undergo a massive displacement, Lee's newfound enlightenment in how to reorganize a post-work society were underwhelming at best, or as I feel is more likely, merely insincere poetry. He proposes a new culture code for society, around the principles of human love, service, and compassion, over present imperatives to find productivity. His transformation story, both for himself and for society land a bit clumsily: his personal transformation from human-turned-work-algorithm to friend and teacher read as an abrupt turn: an out of place single chapter in the book.\n By the end of the book, I felt I had a plausible and detailed thesis for how Chinese entrepreneurs might compete with their American counterparts. I understood the advantages that Chinese businesses wield, and the role the Chinese culture and government may play in that transition. The latter half of the book read more clumsily. Lee’s arguments for how we may transform society to avoid dramatic social upheaval were well considered, though less insightful, and more castle-in-the-sky than his exposition on the Chinese technology story.\n  Rating  First half (6 chapters): information dense enough for a 9/10.\n Second half: often off topic, with a cancer story, an underdeveloped thesis for post-work social change, punctuated with emotionally disingenuous personal anecdotes. 5/10\n Total: 7/10\n  ","description":"","tags":["ai","tech","china","book"],"title":"Review of Ai Superpowers: China, Silicon Valley, and the New World Order, by Kai Fu Lee","uri":"/posts/ai_superpowers/"},{"categories":["society"],"content":" Introduction  “The speed with which human rights has penetrated every corner of the globe is astounding. Compared to human rights, no other system of universal values has spread so far so fast…. In what amounts to a historical blink of the eye, the idea of human rights has become the lingua franca of international morality” (Normand 8). With the simultaneous rise of secularism and the middle class in colonial Europe in the 19th Century, so rose the need for the decoupling of moral justifications for imperialism from religious precedents. Human rights left the sacred behind as a construction of universal humanist norms, to inspire the support of a rising middle class in a modernizing Europe. By donning the vestiges of moral supremacy, Europeans gained new justification for civilizing, educating, and employing the next century of colonial labor, while stemming criticisms of the rising bourgeois class. Human rights have always been a farce, and they remain expensive moral umbrage for nations and the elite.\n The International Criminal Court, established in 2002, took ten years before its first successful prosecution, of Congolese warlord Thomas Lubanga Dyilo. The cost of the ICC, in the first 10 years, exceeds 1 billion dollars. The major international criminal courts in aggregate exceed 6 billion dollars (Stuart 968). The United States, on whom much of the funding and legitimacy for international human rights relies, maintains immunity for its citizens by the 2002 American Service Members’ Protection Act. The rise of political rivals, most prominently Brazil, Russia, India, China, and South Africa, to American and European power, present a valid challenge to the underlying assumption embedded in the most basic premise of human rights: can human rights be truly universal, or are these simply the last vestiges of the once religious, now secular, hypocrite phoenix of moral supremacy? In an examination of the accomplishments of human rights through four eras, I’ll attempt to disentangle the self-aggrandizing mythos of human rights from reality.\n Ford, S. “How Leadership in International Criminal Law is Shifting from the U.S. to Europe and Asia: An Analysis of Spending on Contributions to International Criminal Courts (2011). Saint Louis University Law Journal, Vol. 55, p. 953. Normand, R., Zaidi, S. “Human Rights at the UN: The Political History of Universal Justice” (2008). Bloomington: Indiana University Press.\n  1776-1947: Era of The Bourgeoisie, Secularism, and Capitalism  The modern age of human rights very little resembles its prehistory. Democracies and autocracies, including monarchies, have vastly different requirements of their populations and legal frameworks. Democracies are held to higher standards of justification for political action. The overthrow of European monarchs marks one of the more productive eras in de-facto human rights development, though the language of human rights is mostly a post World War II invention.\n While difficult to quantify, one can reasonably hypothesize that the great advances of this era in human rights is the product of the success of popular uprisings, and the initial successes of expanding democracy, and its deceleration in the 20th century represents conflict of haves and have-nots: wealthy democratic countries have no more incentive than wealthy autocratic ones to preserve the human rights of other nations, especially when these rights conflict with at-home economic interests.\n At the beginnings of the Age of Exploration, beginning with Portueguese navigators in the 15th and 16th Century, monarchs had little need of moral justification towards the end colonizing and enslaving. In the twin, unrivaled power structures of church and state, were generally sufficient justifications for expansion of empire in the name of God and country. But the trappings of exploration produced rivals to the landed elite: the bourgeoisie, in whom the elites invested.\n The British, with far-flung colonies and powerful shipping merchants bore witness to this. The Declaration of Independence, penned by American plantation owner Thomas Jefferson, is the product of the realization by American bourgeoisie that they possess sufficient wealth to contest, and even field armies against traditional monarchical power. Jefferson couches protestations towards monarchal Europe in proto-human rights declarations of offenses by the crown, violating “certain unalienable Rights, that among these are Life, Liberty and the pursuit of Happiness.” The American Constitution re-affirms and cements the political rights of American citizens in The Bill of Rights albeit, excluding most of the population.\n Two decades later, revolutionaries in France mirror the American uprising, and take advantage of the financially drained Louis XVI to declare their rights as justification for revolution in The French Declaration of the Rights of Man. The age of the bourgeoisie, while still exclusionary to the vast majority of citizens, makes the beginnings of human rights discussion possible. But by this point in history, rights are not declared by top-down organizations and governments, but are the product of bottom-up uprisings.\n The year 1848, known as the Spring of Nations, brought a wave of popular uprisings across over 50 countries in Europe (Evans). The revolutions mostly aimed to overthrow monarchical power, while demanding democracy, freedom for the press, and rights for the working class. These rebellions were mostly secular: religious leaders traditionally worked in concert with monarchs suppress challenges to existing power structures. The revolutions succeeded to varying degrees at establishing democracies, but the agitation for a definitive set of rights, was impossible for elites to ignore. European humanist norms grew out of the revolutions, supporting the rights of the newly established bourgeois.\n These rights would come under assault in the first half of the 20th Century. The twin cataclysms of the World Wars reduced Western Europe to rubble, allowing the advancing American economy to surpass its European forebears. The devastating effects of the world wars also propelled the advance of democracy and capitalism in Western Europe, and communist dictatorship in Eastern Europe. The positive narrative identifies this struggle as that of competing ideologies in a brawl of how best to assert the political and social rights against a Hobbsian struggle of all against all. The remaining powers needed new language to justify the shattered myths of the previous century, asserting that humanist rights existed, and could not be abused at any time by the existing power structures, as they had been in the world wars.\n It’s worth noting that each of the participants in the Second World War abused and repressed citizens in a major way. Though this list is hardly exhaustive: Jim Crow in the United States, colonial oppression by Western Powers, barbaric war crimes by the Japanese, and genocides by Nazis and Soviets. These were the powers submitting diplomats to pen the first modern document of Human Rights, the Universal Declaration of Human Rights (UDHR). This stands in sharp contrast to the emergence of rights following popular uprisings in the 18th and 19th Centuries.\n R.J.W. Evans and Hartmut Pogge von Strandmann, eds., The Revolutions in Europe 1848–1849 (2000) pp. v, 4\n Declaration of Independence, Paragraph 2 (1776).\n  1947-1976: Era of The Universal Declaration of Human Rights   In the aftermath of the Second World war, world leaders gathered in Paris to pen the UDHR. According to international law professor Stephen Hopgood in The Endtimes of Human Rights, the UDHR was “an antidote to a troubling contradiction, the coexistence of progress with intensifying violence, vast social and economic inequality, and fears of “the disenchantment of the world” (Hopgood 1).\n The modern language of human rights was borne out of the need for a neutral and secular ideology for developed nations to use as a neutered critique of one another, to limit risk of a third world war. European and American leaders sought to weave into the UDHR an ideological alibi for a new globalized economic system designed to promote international collaboration, benefitting the elites, while only supporting an enhanced sentimentality for human rights in tongue. The UDHR, therefore was a set of thirty non-binding articles, agreed upon by world leaders, but not to be taken seriously. Economist Eric Posner writes in The Twilight of Human Rights “the words in the Universal Declaration may have been stirring, but no one believed at the time that they portended a major change in the way international relations would be conducted, nor did they capture the imagination of voters, politicians, intellectuals, leaders of political movements, or anyone else who might have exerted political pressure on governments” (Posner 17).\n Why were the articles non-binding? The authors of the UDHR were not the surviving revolutionaries seeking to validate the rights of humans against their former governments, but the ambassadors of the most powerful nations, who sought to reaffirm their hegemonic power by a set of tacit agreements to not challenge one another militarily. These diplomats were not defending human rights in the sense that human rights protect people from their governments: they were protecting their nations, developed nations, from the threat of war. Any illusion of possible agreement concerning universal ideals was quickly dispelled: there were clashes between the United States diplomat, Elanor Roosevelt, with the Soviets concerning rights to property and political freedoms, opposition by the Saudis towards articles concerning freedom of religion, Latin American diplomats who wanted God mentioned, and fears of colonial intervention by the British and French, while the Japanese were to be stripped of their recent colonial acquisitions (Loeffler).\n The effects of the UDHR on human rights around the world were underwhelming. The United Nations established a commission for responding to human rights complaints. In the first ten years of operation, roughly 65,000 letters alleging human rights violations arrived at this newly minted defender of human rights. The commission declined to investigate a single complaint (Loeffler). Issues emerged as larger powers did not want to risk upsetting the power balance between the Soviet Union and the United States, potentially triggering war, and smaller powers had neither the political capital, resources, nor incentive to begin investigations. The UDHR proved an empty set of nice sounding words. This was not unexpected, even at the outset: according to international law expert Hersch Laueterpacht in 1947, “to a lawyer, the enunciation of a right without the provision of a remedy is a judicial heresy…It is clear to me that the declaration does not carry things further and that in some important respects has put the clock back.” (Loeffler)\n Loeffler, J. (2018, December 21) “Human rights treaties promised a better future. Why did they fail?”. Washington Post. Hopgood, S. (2015). The Endtimes of Human Rights. Ithaca: Cornell University Press. Posner, E. (2014). Twilight of Human Rights Law. Oxford University Press.\n  1976-1991: Era of Human Rights Treaty Proliferation and American Money   The modern age of human rights organizations begins in earnest in the 1970s with the International Covenant on Economic, Social and Cultural Rights (ICESCR) and the International Covenant on Civil and Political Rights (Moyn). The covenants were intended as an expansion of the UDHR, but this time, gave overseeing commissions more power to enforce violations. The covenants were contemplated as early as 1948, by American historian Arthur Holcombe, as “a project for a piece of international legislation, more ambitious and perhaps more important than any other in the history of international law. If supported by suitable measures of implementation, it could be a great triumph of reason over force and violence in the development of human relations.” (Holcombe, 413)\n Thus, the 1970s represent the shifting tide of human rights from general irrelevance to a proliferation of human rights treaties, to mixed effect. Some of these genuinely treated human rights issues, ie. Convention on the Elimination of Discrimination Against Women (CEDAW), while others were microcosms of the symbolic battles between the United States and the Soviet Union. The United States used human rights law as political leverage against the Soviet Union, while in exchange for ideological concessions, the Soviets bought recognition of autonomy in determining the freedoms of Eastern Europe.\n The beginnings of American involvement in human rights in the 1970’s signaled the end of a unipolar European human rights era, though for a time human rights became unipolar about the American-centric perspectives, a phenomena that strengthened after the collapse of the Soviet Union, and has only in the last decade seen significant challenges by economic competitors to the United states, most prominently China. The era of American influence saw the demise of what Hopgood describes as European “secular religiosity” and towards the American style of political intervention in the name of defending democracy—where democracy was a thinly veiled stand-in for American economic interests. Recent examples include American ongoing relations with Saudi Arabia, 1990s support Saddam Hussain in Iraq, and strategic support of torture in Guantanamo Bay.\n The Americans, even under the most ardent human rights supporter, President Carter, were inconsistent allies to the human rights endeavor: “human-rights violating allies like Iran and Saudi Arabia were just too important for American security, and seen as an important counterweight to Soviet influence, so Carter could not consistently follow through on his rhetoric by threatening to withhold diplomatic support or economic resources from some of the worst violators of human rights” (Posner 18). While the United States generally supported and provided funding for major human rights organizations, they seldom ratified human rights treaties, and only with a raft of Reservations, Understandings, and Declarations (RUDs) limiting the United States’ liability to upholding the treaty.\n Not that this was likely even necessary. Many authoritarian countries ratified the ICCPR, and other human rights treaties, and although these treaties were designed to be more binding, the same issue of political non-incentive for any particular country to take action resurfaced. Further, the treaties often used vague, sometimes self-negating language, or specified requirements that would be aspirational for all but the richest countries. Article 19 of the ICCPR declares the right to freedom of expression, but in the next paragraph, offers governments a get-out clause:\n  Everyone shall have the right to freedom of expression; this right shall include freedom to seek, receive and impart information and ideas of all kinds, regardless of frontiers, either orally, in writing or in print, in the form of art, or through any other media of his choice.\n  The exercise of the rights provided for in paragraph 2 of this article carries with it special duties and responsibilities. It may therefore be subject to certain restrictions, but these shall only be such as are provided by law and are necessary: (a) For respect of the rights or reputations of others; (b) For the protection of national security or of public order (ordre public), or of public health or morals.\n  The gates of plausible deniability in the clause, “protection of national security or of public order.. or morals,” swing wide. The failings of the covenants were appreciated at the time. Pakistani legal scholar, Hamid Kizilbash wrote of the covenants in 1976 that “what is most unsatisfactory about the implementation procedure is the fact that the individual has no role in the preparation of reports. States are not called upon to consult or transmit what an individual group within their territory may wish to have included in the report. No system of hearings, public consultation and individual petitions has been provided for. In the absence of such provisions it is clear that the reports will reflect whatever the government of a state wishes to make known” (Kizilbash 57).\n Holcombe, A.N. \"The Covenants on Human Rights\", Law and Contemporary Problems, 14 (Summer 1948), pp. 413-429. International Covenant on Civil and Political Rights, Article 19 (1966). Kizilbash, H. “United Nations and Human Rights: A Failure Report” (1974). Pakistan Horizon Vol. 27, No. 1 (First Quarter, 1974), pp. 50-60 Moyn, S. (2010). The Last Utopia. Harvard University Press.\n  1991-now: Era of American Pseudo-Unipolarity  In the wake of the fall of the Soviet Union, one might reasonably assume a raft of advances human rights could proceed, over the corpse of their most powerful political opponent. However, immediately following the fall of the Soviet Union, events made a mockery of such an assumption. First, the horrifying genocide in Rwanda, where more than 800,000 Tutsis were slaughtered by the Hutu majority in Rwanda (Posner). The event was made for macabre spectator sport for the human rights organizations of Europe, demonstrating the irrelevance of the now nearly 50 year old Convention on the Prevention and Punishment of the Crime of Genocide and the commission appointed to advise the UN. The lesson repeated itself one year later in the civil war in Yugoslavia where Serbians attempted to ethnically cleanse Bosnians from the region, shocking Europeans to see genocide return once more in the 20th Century to their own continent.\n The war criminal trials that followed (the UN was basically immobile during the atrocities) were widely criticized for bias and inconsistency, leading to the establishment of the International Criminal Court in 1998, and official opening in 2002. It has tried few, successfully tried fewer, and those it has tried are exclusively from African nations. The court took 10 years before its first successful prosecution, of the Congolese warlord Thomas Lubanga Dyilo. It is also expensive, costing a billion dollars in its first decade. The United States continues to claim immunity to the court, and refuses to provide funding for the court. Naturally, the court appears mostly irrelevant.\n According to Freedom House, every year since 2005 has seen a retreat in democracy and an advance of authoritarianism. Modern democracy has seen a corresponding retreat of the notion of the public space where facts exist as universal. Propaganda experts in Russia successfully used data, with the aid of data company Cambridge Analytica to spread disinformation about political events in the United States and the United Kingdom leading up to the 2016 election, and the Brexit referendum. Facebook has set new norms for the public dialogue between fiction and fact, allowing disinformation to be spread, while making surveillance easier than ever before (Snyder). Democracy has succumbed to populism in Hungary, Poland, Brazil, and Bosnia in the last decade. Human rights efforts, by contrast, appear to be stuck in the 19th century.\n In 2017 the Office of the High Commissioner for Human Rights launched their 70th year anniversary campaign. The campaign feature the hashtag, #standup4humanrights, along with a website proclaiming “we can all be Human Rights Champions.” The website encouraged participants to post stories online, on platforms including Snapchat, Instagram, and yes, Facebook, the last of whom there has received no official comment on, or criticism of, by any of the human rights commissions at the UN. “All it takes, apparently, is posting individual stories online and recording an article of the declaration in one’s own language. There is hardly any mention of law or politics; it suffices to ‘promote, engage and reflect.’” (Loeffler)\n Snyder, T. (May 21, 2018) “Facism is back. Blame the Internet.” Washington Post.\n  Conclusion  Throughout this essay, I’ve alluded to the differences between revolutionaries’ claims to rights, and governments’ self-justification via an invented language of international law. Hopgood explains the difference between top-down human and bottom-up human rights as follows, “the local and transnational network of activists who bring publicity to abuses they and their communities face and who try to exert pressure on governments and the United Nations for action, often at tremendous personal cost”, versus “a global structure of laws, courts, norms, organizations that raise money, write reports, run international campaigns, open local offices, lobby governments, and claim to speak with singular authority in the name of humanity as a whole” (Hopgood 2). The criticism reflects the conflict of liberal versus the libertarian, in the question, does greater bureaucracy correspond to gains in human potential, or is the growth that of a cancer, whose purpose is not to serve the body out of which it was conceived, but only to grow?\n This central conflict plays out while human rights activists engage bottom-up, grassroots endeavors around the world. These countries lie beyond the political purview of the International Criminal Court in the Hague, struggling against the rise of tyranny and nationalism in places like Bolivia, Venezuela, China, and Russia. Resistance movements can only seldom rely on the international bureaucracy to provide the assistance promised in lofty covenants. If human rights organizations had any legitimate influence, the Arab Spring would have been unnecessary, and dictators in Egypt and Syria would have been replaced by human rights leaders. Instead, politicians in countries like the United States and Russia used human rights declarations as pawns to maintain economic interests in the region.\n What is unconscionable is that human rights organizations continue to ignore criticism of the failings of the movement. Foreign policy analyst David Rieff wrote of this phenomenon of cognitive dissonance, “This is predictable. If your expectations are millenarian — if you believe there is a right side of history, yours, and a wrong side of history that is doomed to defeat — skepticism about the human rights project, let alone voices of opposition, is unlikely to sway your position” (Rieff). Human rights activists need to justify the unmerited and costly expansion of their bureaucracies. Human rights documents need to have more substantial teeth than the possibility that a commission will enter into dialogue with a violating nation. The failures of human rights organizations are costly not only in price but in their deception: allowing nations to do the bare minimum to defend democracy and free people around the world.\n Rieff, E. “The End of Human Rights?” (April 9, 2018). Foreign Policy Magazine.\n  ","description":"a pessimistic insistance on honesty in the story of human rights history","tags":["human rights","history","school","politics"],"title":"Human Rights: Entertaining the Illusion","uri":"/posts/four_floundering_eras_of_human_rights/"}]
